# handlers/commands/teach.py
from __future__ import annotations
import re
from telegram import Update
from telegram.ext import (
    ContextTypes,
    ConversationHandler,
    CommandHandler,
    CallbackQueryHandler,   # ‚Üê –¥–æ–±–∞–≤–∏–ª–∏
    MessageHandler,
    filters,
)
from components.training_db import set_consent, has_consent, add_glossary, get_glossary

__all__ = [
    "build_teach_handler",
    "teach_start",
    "glossary_cmd",
    "consent_on",
    "consent_off",
]

ASK_SRC_DST = 1
ASK_LIST    = 2
ASK_CORR    = 3  # fallback –¥–ª—è –æ–¥–∏–Ω–æ—á–Ω–æ–π –ø–∞—Ä—ã (—Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç—å)

_SEP_VARIANTS = [" ‚Äî ", " - ", " -> ", " ‚Üí ", "‚Äî", "-", "->", "‚Üí"]

_LANG_PAIR_RE = re.compile(
    r"^\s*([A-Za-z]{2})\s*(?:-|‚Äî|->|‚Üí|\s)\s*([A-Za-z]{2})\s*$"
)

_BAD_RU = [
    r"\b—Ö—É–π\b", r"\b—Ö—É–µ", r"\b–ø–∏–∑–¥", r"\b–±–ª—è–¥", r"\b–µ–±–∞—Ç", r"\b–µ–±–∞–Ω", r"\b—Å—É–∫–∞\b",
    r"\b—Å—É–∫–∏\b", r"\b–º—Ä–∞–∑", r"\b—É–±–ª—é–¥", r"\b–≥–æ–≤–Ω", r"\b–¥–µ—Ä—å–º"
]
_BAD_EN = [
    r"\bfuck", r"\bshit\b", r"\basshole\b", r"\bbitch\b", r"\bdick\b", r"\bcunt\b",
    r"\bslut\b", r"\bwhore\b"
]
_BAD_RE = re.compile("(" + "|".join(_BAD_RU + _BAD_EN) + ")", re.IGNORECASE)


def _split_pair(text: str):
    for sep in _SEP_VARIANTS:
        if sep in text:
            a, b = text.split(sep, 1)
            return a.strip(), b.strip()
    m = re.match(r'^\s*"?(.+?)"?\s*[-‚Äî‚Üí>]+\s*"?(.+?)"?\s*$', text)
    if m:
        return m.group(1).strip(), m.group(2).strip()
    return None, None


def _contains_bad_words(s: str) -> bool:
    return bool(_BAD_RE.search(s or ""))


def _parse_lang_pair(s: str):
    m = _LANG_PAIR_RE.match((s or ""))
    if not m:
        return None, None
    return m.group(1).lower(), m.group(2).lower()


# --------- –°–û–ì–õ–ê–°–ò–ï –ù–ê –†–ï–ñ–ò–ú TEACH ----------
async def consent_on(update: Update, ctx: ContextTypes.DEFAULT_TYPE):
    set_consent(update.effective_user.id, True)
    await update.effective_message.reply_text(
        "‚úÖ –†–µ–∂–∏–º –∫–æ—Ä—Ä–µ–∫—Ç–∏—Ä–æ–≤–æ–∫ –≤–∫–ª—é—á—ë–Ω.\n\n"
        "–ö–∞–∫ –ø–æ–ª—å–∑–æ–≤–∞—Ç—å—Å—è:\n"
        "1) –û—Ç–ø—Ä–∞–≤—å —è–∑—ã–∫–æ–≤—É—é –ø–∞—Ä—É –¥–≤—É–º—è –±—É–∫–≤–∞–º–∏: en-ru, ru-en, en-fi‚Ä¶ –ï—Å–ª–∏ —Å–æ–º–Ω–µ–≤–∞–µ—à—å—Å—è ‚Äî /codes.\n"
        "2) –ó–∞—Ç–µ–º —Å–ø–∏—Å–∫–æ–º –ø—Ä–∏—à–ª–∏ —Å—Ç—Ä–æ–∫–∏ ¬´—Ñ—Ä–∞–∑–∞ ‚Äî –ø–µ—Ä–µ–≤–æ–¥¬ª, –ø–æ –æ–¥–Ω–æ–π –Ω–∞ —Å—Ç—Ä–æ–∫–µ.\n\n"
        "–í–∞–∂–Ω–æ: —ç—Ç–æ –¥–≤–∞ —Ä–∞–∑–Ω—ã—Ö —Å–æ–æ–±—â–µ–Ω–∏—è ‚Äî —Å–Ω–∞—á–∞–ª–∞ –ø–∞—Ä–∞ —è–∑—ã–∫–æ–≤, –∂–¥–∏ –ø–æ–¥—Ç–≤–µ—Ä–∂–¥–µ–Ω–∏—è, –ø–æ—Ç–æ–º —Å–ø–∏—Å–æ–∫ –ø–∞—Ä.\n\n"
        "–ü—Ä–∏–º–µ—Ä:\n"
        "I feel you ‚Äî –ü–æ–Ω–∏–º–∞—é —Ç–µ–±—è\n"
        "Break a leg ‚Äî –£–¥–∞—á–∏!\n\n"
        "–ì–æ—Ç–æ–≤–æ ‚Äî —è —Å–æ—Ö—Ä–∞–Ω—é –≤—Å—ë –≤ /glossary.\n"
        "–°–ø–∞—Å–∏–±–æ! –¢—ã –¥–µ–ª–∞–µ—à—å –ú—ç—Ç—Ç–∞ –ª—É—á—à–µ ‚ù§Ô∏è"
    )


async def consent_off(update: Update, ctx: ContextTypes.DEFAULT_TYPE):
    set_consent(update.effective_user.id, False)
    await update.effective_message.reply_text(
        "–û–∫–µ–π, —Ä–µ–∂–∏–º –∫–æ—Ä—Ä–µ–∫—Ç–∏—Ä–æ–≤–æ–∫ –≤—ã–∫–ª—é—á–µ–Ω. –í–µ—Ä–Ω—ë—à—å—Å—è ‚Äî —Å–∫–∞–∂–∏ /consent_on üôÇ"
    )


# --------- –í–•–û–î –í –†–ï–ñ–ò–ú TEACH ----------
async def teach_start(update: Update, ctx: ContextTypes.DEFAULT_TYPE):
    if not has_consent(update.effective_user.id):
        await update.effective_message.reply_text("–°–Ω–∞—á–∞–ª–∞ –≤–∫–ª—é—á–∏ —Å–æ–≥–ª–∞—Å–∏–µ: /consent_on üôÇ")
        return ConversationHandler.END

    # –ï—Å–ª–∏ –ø—Ä–∏—à–ª–∏ –ø–æ inline-–∫–Ω–æ–ø–∫–µ ‚Äî –∞–∫–∫—É—Ä–∞—Ç–Ω–æ –æ—Ç–≤–µ—Ç–∏–º –Ω–∞ callback, —á—Ç–æ–±—ã –Ω–µ –≤–∏—Å–µ–ª "—á–∞—Å–∏–∫".
    q = getattr(update, "callback_query", None)
    if q:
        try:
            await q.answer()
        except Exception:
            pass

    await update.effective_message.reply_text(
        "–û—Ç–ø—Ä–∞–≤—å —è–∑—ã–∫–æ–≤—É—é –ø–∞—Ä—É (–Ω–∞–ø—Ä–∏–º–µ—Ä, en-ru –∏–ª–∏ ru-en). –Ø –Ω–∞ —Å–≤—è–∑–∏ üòâ"
    )
    return ASK_SRC_DST


async def teach_src_dst(update: Update, ctx: ContextTypes.DEFAULT_TYPE):
    t = (update.message.text or "").strip()
    src, dst = _parse_lang_pair(t)
    if not src or not dst:
        await update.effective_message.reply_text(
            "–ù—É–∂–Ω–æ —É–∫–∞–∑–∞—Ç—å –ø–∞—Ä—É –¥–≤—É—Ö–±—É–∫–≤–µ–Ω–Ω—ã—Ö –∫–æ–¥–æ–≤: en-ru, en-fi, ru-en, ru-es –∏ —Ç.–¥. –ü–æ–ø—Ä–æ–±—É–µ—à—å –µ—â—ë —Ä–∞–∑? üôÇ\n"
            "–ü–æ–¥—Å–∫–∞–∑–∫–∞ –ø–æ –∫–æ–¥–∞–º ‚Äî /codes"
        )
        return ASK_SRC_DST

    ctx.user_data["teach_src"], ctx.user_data["teach_dst"] = src, dst
    await update.effective_message.reply_text(
        "–ü—Ä–∏–Ω—è—Ç–æ! –¢–µ–ø–µ—Ä—å –ø—Ä–∏—à–ª–∏ —Å–ø–∏—Å–æ–∫ —Å—Ç—Ä–æ–∫ ¬´—Ñ—Ä–∞–∑–∞ ‚Äî –ø–µ—Ä–µ–≤–æ–¥¬ª (–ø–æ –æ–¥–Ω–æ–π –Ω–∞ —Å—Ç—Ä–æ–∫–µ).\n"
        "–ù–∞–ø—Ä–∏–º–µ—Ä:\n"
        "I feel you ‚Äî –ü–æ–Ω–∏–º–∞—é —Ç–µ–±—è\n"
        "Break a leg ‚Äî –£–¥–∞—á–∏!"
    )
    return ASK_LIST


def _parse_pairs_block(block: str) -> list[tuple[str, str]]:
    pairs: list[tuple[str, str]] = []
    for raw_line in (block or "").splitlines():
        line = raw_line.strip()
        if not line:
            continue
        p, c = _split_pair(line)
        if p and c:
            pairs.append((p, c))
    return pairs


async def teach_list(update: Update, ctx: ContextTypes.DEFAULT_TYPE):
    src = ctx.user_data.get("teach_src", "en")
    dst = ctx.user_data.get("teach_dst", "ru")
    block = (update.message.text or "").strip()

    pairs = _parse_pairs_block(block)

    if not pairs:
        ctx.user_data["teach_phrase"] = block
        await update.effective_message.reply_text(
            "–ù—É–∂–µ–Ω —Ñ–æ—Ä–º–∞—Ç ¬´—Ñ—Ä–∞–∑–∞ ‚Äî –ø–µ—Ä–µ–≤–æ–¥¬ª, –ø–æ –æ–¥–Ω–æ–π –ø–∞—Ä–µ –Ω–∞ —Å—Ç—Ä–æ–∫–µ. –ü–æ–ø—Ä–æ–±—É–µ–º –µ—â—ë —Ä–∞–∑? üôÇ"
        )
        return ASK_CORR

    saved = []
    skipped_bad = 0
    for phrase, corr in pairs:
        if _contains_bad_words(phrase) or _contains_bad_words(corr):
            skipped_bad += 1
            continue
        add_glossary(update.effective_user.id, src, dst, phrase, corr)
        saved.append(f"{phrase} ‚Äî {corr}")

    if not saved and skipped_bad > 0:
        await update.effective_message.reply_text(
            "‚ùå –ù–µ —Å–æ—Ö—Ä–∞–Ω–∏–ª: –Ω–∞–π–¥–µ–Ω –Ω–µ–Ω–æ—Ä–º–∞—Ç–∏–≤–Ω—ã–π –∫–æ–Ω—Ç–µ–Ω—Ç. –î–∞–≤–∞–π –±–µ–∑ —ç—Ç–æ–≥–æ, –æ–∫? üòâ"
        )
        return ConversationHandler.END

    if saved:
        header = "‚úÖ –í—Å—ë –ø–æ–ª—É—á–∏–ª–æ—Å—å, —Å–ø–∞—Å–∏–±–æ!\n–í –≥–ª–æ—Å—Å–∞—Ä–∏–π –¥–æ–±–∞–≤–ª–µ–Ω–æ:\n"
        body = "\n".join(saved[:50])
        footer = "\n\n–ï—â—ë –ø—Ä–∏–º–µ—Ä—ã ‚Äî —Å–Ω–æ–≤–∞ /teach. –ü–æ—Å–º–æ—Ç—Ä–µ—Ç—å ‚Äî /glossary."
        if skipped_bad:
            footer += f"\n(–ü—Ä–æ–ø—É—â–µ–Ω–æ –∏–∑-–∑–∞ –Ω–µ–Ω–æ—Ä–º–∞—Ç–∏–≤–Ω–æ–π –ª–µ–∫—Å–∏–∫–∏: {skipped_bad})"
        await update.effective_message.reply_text(header + body + footer)
    else:
        await update.effective_message.reply_text(
            "–Ø –Ω–µ —É–≤–∏–¥–µ–ª –ø–∞—Ä ¬´—Ñ—Ä–∞–∑–∞ ‚Äî –ø–µ—Ä–µ–≤–æ–¥¬ª. –ü—Ä–∏—à–ª–∏ –∏—Ö –ø–æ –æ–¥–Ω–æ–π –Ω–∞ —Å—Ç—Ä–æ–∫–µ.\n"
            "–ù–∞–ø—Ä–∏–º–µ—Ä: I feel you ‚Äî –ü–æ–Ω–∏–º–∞—é —Ç–µ–±—è üôÇ"
        )

    return ConversationHandler.END


async def teach_correction(update: Update, ctx: ContextTypes.DEFAULT_TYPE):
    # Fallback: –æ–¥–∏–Ω–æ—á–Ω–∞—è –ø–∞—Ä–∞ (—Å—Ü–µ–Ω–∞—Ä–∏–π —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç–∏)
    src = ctx.user_data.get("teach_src", "en")
    dst = ctx.user_data.get("teach_dst", "ru")
    phrase = ctx.user_data.get("teach_phrase")
    corr = (update.message.text or "").strip()
    if not phrase:
        p, c = _split_pair(corr)
        if p and c:
            phrase, corr = p, c

    if not phrase or not corr:
        await update.effective_message.reply_text(
            "–ù—É–∂–Ω—ã –¥–≤–µ —á–∞—Å—Ç–∏: ¬´—Ñ—Ä–∞–∑–∞ ‚Äî –ø–µ—Ä–µ–≤–æ–¥¬ª. –ü–æ–ø—Ä–æ–±—É–π –µ—â—ë —Ä–∞–∑ —á–µ—Ä–µ–∑ /teach? üôÇ"
        )
        return ConversationHandler.END

    if _contains_bad_words(phrase) or _contains_bad_words(corr):
        await update.effective_message.reply_text("‚ùå –ù–µ —Å–æ—Ö—Ä–∞–Ω–∏–ª: –Ω–∞–π–¥–µ–Ω –Ω–µ–Ω–æ—Ä–º–∞—Ç–∏–≤–Ω—ã–π –∫–æ–Ω—Ç–µ–Ω—Ç.")
        return ConversationHandler.END

    add_glossary(update.effective_user.id, src, dst, phrase, corr)
    await update.effective_message.reply_text("‚úÖ –ì–æ—Ç–æ–≤–æ. –ï—â—ë ‚Äî /teach. –ü–æ—Å–º–æ—Ç—Ä–µ—Ç—å ‚Äî /glossary.")
    return ConversationHandler.END


async def glossary_cmd(update: Update, ctx: ContextTypes.DEFAULT_TYPE):
    rows = get_glossary(update.effective_user.id)
    if not rows:
        await update.effective_message.reply_text(
            "–ü–æ–∫–∞ –ø—É—Å—Ç–æ. –î–æ–±–∞–≤—å –ø–∞—Ä—ã —á–µ—Ä–µ–∑ /teach ‚Äî –∏ –∑–¥–µ—Å—å –ø–æ—è–≤–∏—Ç—Å—è —Ç–≤–æ–π –º–∏–Ω–∏-—Å–ª–æ–≤–∞—Ä—å. ‚úçÔ∏è"
        )
        return
    lines = []
    for src, dst, phrase, corr in rows[:200]:
        lines.append(f"{src}‚Üí{dst}: {phrase} ‚Äî {corr}")
    await update.effective_message.reply_text("\n".join(lines))


def build_teach_handler():
    return ConversationHandler(
        entry_points=[
            CommandHandler("teach", teach_start),
            CallbackQueryHandler(teach_start, pattern=r"^open:teach$"),  # –∫–ª–∏–∫ –∏–∑ –º–µ–Ω—é
        ],
        states={
            ASK_SRC_DST: [MessageHandler(filters.TEXT & ~filters.COMMAND, teach_src_dst)],
            ASK_LIST:    [MessageHandler(filters.TEXT & ~filters.COMMAND, teach_list)],
            ASK_CORR:    [MessageHandler(filters.TEXT & ~filters.COMMAND, teach_correction)],
        },  # ‚Üê –í–ê–ñ–ù–û: –∑–∞–∫—Ä—ã–≤–∞–µ–º —Ñ–∏–≥—É—Ä–Ω–æ–π —Å–∫–æ–±–∫–æ–π
        fallbacks=[CommandHandler("cancel", lambda u, c: u.message.reply_text("–û—Ç–º–µ–Ω–µ–Ω–æ"))],
        allow_reentry=True,
        per_message=False,
    )
