import os
import time
import random
import re
import tempfile
import logging
from html import unescape  # NEW: –¥–ª—è –±–µ–∑–æ–ø–∞—Å–Ω–æ–≥–æ plain-–¥—É–±–ª—è
from telegram import Update
from telegram.ext import ContextTypes

from config.config import ADMINS, OPENAI_API_KEY
from openai import OpenAI  # –Ω–æ–≤—ã–π –∫–ª–∏–µ–Ω—Ç –¥–ª—è ASR

from components.gpt_client import ask_gpt
from components.voice import synthesize_voice
from components.mode import MODE_SWITCH_MESSAGES, get_mode_keyboard
from state.session import user_sessions
from handlers.chat.prompt_templates import get_system_prompt
from components.triggers import CREATOR_TRIGGERS, MODE_TRIGGERS
from components.triggers import is_strict_mode_trigger, is_strict_say_once_trigger
from components.code_switch import rewrite_mixed_input  # ‚Üê NEW

logger = logging.getLogger(__name__)

oai_asr = OpenAI(api_key=OPENAI_API_KEY) if OPENAI_API_KEY else None

MAX_HISTORY_LENGTH = 40
RATE_LIMIT_SECONDS = 1.5

LANGUAGE_CODES = {
    "en": "en-US",
    "fr": "fr-FR",
    "de": "de-DE",
    "es": "es-ES",
    "ru": "ru-RU",
    "sv": "sv-SE",
    "fi": "fi-FI",
}


def get_greeting_name(lang: str) -> str:
    return "Matt" if lang == "en" else "–ú—ç—Ç—Ç"


def _sanitize_user_text(text: str, max_len: int = 2000) -> str:
    text = (text or "").strip()
    if len(text) > max_len:
        text = text[:max_len]
    return text


def _strip_html(s: str) -> str:
    """–£–¥–∞–ª—è–µ–º HTML-—Ç–µ–≥–∏ –∏ –¥–µ–∫–æ–¥–∏—Ä—É–µ–º —Å—É—â–Ω–æ—Å—Ç–∏ –¥–ª—è –±–µ–∑–æ–ø–∞—Å–Ω–æ–≥–æ plain-—Ç–µ–∫—Å—Ç–∞."""
    return re.sub(r"<[^>\n]+>", "", unescape(s or ""))


async def _send_voice_or_audio(context: ContextTypes.DEFAULT_TYPE, chat_id: int, file_path: str):
    """
    –ï—Å–ª–∏ .ogg ‚Äî —à–ª—ë–º –∫–∞–∫ voice, –∏–Ω–∞—á–µ (.mp3) ‚Äî –∫–∞–∫ audio.
    """
    if file_path.lower().endswith(".ogg"):
        with open(file_path, "rb") as vf:
            await context.bot.send_voice(chat_id=chat_id, voice=vf)
    else:
        with open(file_path, "rb") as af:
            await context.bot.send_audio(chat_id=chat_id, audio=af)


# --- –ì–ª–∞–≤–Ω—ã–π message handler ---
async def handle_message(update: Update, context: ContextTypes.DEFAULT_TYPE):
    chat_id = update.effective_chat.id
    session = user_sessions.setdefault(chat_id, {})

    # === –ï—Å–ª–∏ –∂–¥—ë–º –ø—Ä–æ–º–æ–∫–æ–¥ ‚Äî –¥–µ–ª–µ–≥–∏—Ä—É–µ–º –∏ –≤—ã—Ö–æ–¥–∏–º ===
    try:
        stage = session.get("onboarding_stage")
    except Exception:
        stage = None
    if stage == "awaiting_promo":
        from components.onboarding import promo_code_message
        return await promo_code_message(update, context)

    # --- RATE LIMITING ---
    now = time.time()
    last_time = session.get("last_message_time", 0)
    if now - last_time < RATE_LIMIT_SECONDS:
        await context.bot.send_message(chat_id=chat_id, text="‚è≥ –ü–æ–≥–æ–¥–∏, –¥—É–º–∞—é üôÇ")
        return
    session["last_message_time"] = now

    try:
        # --- session defaults ---
        session.setdefault("interface_lang", "en")
        session.setdefault("target_lang", "en")
        session.setdefault("level", "A2")
        session.setdefault("mode", "text")
        session.setdefault("style", "casual")

        # --- –î–æ—Å—Ç–∞—ë–º –∑–Ω–∞—á–µ–Ω–∏—è –∏–∑ —Å–µ—Å—Å–∏–∏ ---
        interface_lang = session["interface_lang"]
        target_lang = session["target_lang"]
        level = session["level"]
        mode = session["mode"]
        style = session["style"]

        # === –í—Ö–æ–¥: –≥–æ–ª–æ—Å –∏–ª–∏ —Ç–µ–∫—Å—Ç ===
        if update.message.voice:
            if not oai_asr:
                await context.bot.send_message(chat_id=chat_id, text="‚ùóÔ∏èASR –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω. –ü–æ–ø—Ä–æ–±—É–π –µ—â—ë —Ä–∞–∑ –ø–æ–∑–∂–µ.")
                return

            voice_file = await context.bot.get_file(update.message.voice.file_id)
            with tempfile.NamedTemporaryFile(suffix=".ogg", delete=False) as tf:
                await voice_file.download_to_drive(tf.name)
                audio_path = tf.name
            try:
                with open(audio_path, "rb") as f:
                    # –ù–æ–≤—ã–π –∫–ª–∏–µ–Ω—Ç: –±–µ–∑ response_format="text"
                    tr = oai_asr.audio.transcriptions.create(
                        model="whisper-1",
                        file=f,
                    )
                user_input = (getattr(tr, "text", "") or "").strip()
                logger.info("Whisper recognized text: %r", user_input)
            except Exception:
                await context.bot.send_message(chat_id=chat_id, text="‚ùóÔ∏è–û—à–∏–±–∫–∞ —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏—è –≥–æ–ª–æ—Å–∞. –ü–æ–ø—Ä–æ–±—É–π –µ—â—ë —Ä–∞–∑.")
                logger.exception("[Whisper Error]")
                user_input = ""
            finally:
                try:
                    os.remove(audio_path)
                except Exception as e_rm:
                    logger.warning("Failed to remove temp audio: %s", e_rm)
        else:
            user_input = update.message.text or ""

        user_input = _sanitize_user_text(user_input, max_len=2000)
        if not user_input:
            await context.bot.send_message(chat_id=chat_id, text="‚ùóÔ∏è–ü–æ—Ö–æ–∂–µ, —Å–æ–æ–±—â–µ–Ω–∏–µ –Ω–µ —Ä–∞—Å–ø–æ–∑–Ω–∞–Ω–æ. –°–∫–∞–∂–∏ —á—Ç–æ-–Ω–∏–±—É–¥—å –µ—â—ë üôÇ")
            return

        # === –†–∞–∑–æ–≤–∞—è –æ–∑–≤—É—á–∫–∞ –±–µ–∑ —Å–º–µ–Ω—ã —Ä–µ–∂–∏–º–∞ ===
        if is_strict_say_once_trigger(user_input, interface_lang):
            last_text = session.get("last_assistant_text")
            if not last_text:
                if interface_lang == "ru":
                    await update.message.reply_text("–ü–æ–∫–∞ –º–Ω–µ –Ω–µ—á–µ–≥–æ –æ–∑–≤—É—á–∏—Ç—å. –°–Ω–∞—á–∞–ª–∞ –¥–æ–∂–¥–∏—Å—å –º–æ–µ–≥–æ –æ—Ç–≤–µ—Ç–∞, –∞ –ø–æ—Ç–æ–º –Ω–∞–ø–∏—à–∏ ¬´–æ–∑–≤—É—á—å¬ª.")
                else:
                    await update.message.reply_text("I have nothing to voice yet. First wait for my reply, then say ‚Äúvoice it‚Äù.")
                return
            try:
                voice_path = synthesize_voice(
                    last_text,
                    LANGUAGE_CODES.get(target_lang, "en-US"),
                    level,  # —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç—å —É—á—Ç–µ–Ω–∞ –≤ voice.py
                )
                # --- –æ—Ç–ø—Ä–∞–≤–∫–∞ voice ---
                try:
                    if voice_path:
                        await _send_voice_or_audio(context, chat_id, voice_path)
                    else:
                        raise RuntimeError("No TTS data")
                except Exception:
                    await context.bot.send_message(
                        chat_id=chat_id,
                        text="‚ö†Ô∏è –ù–µ —É–¥–∞–ª–æ—Å—å –æ—Ç–ø—Ä–∞–≤–∏—Ç—å –≥–æ–ª–æ—Å. –í–æ—Ç —Ç–µ–∫—Å—Ç:\n" + _strip_html(last_text),
                    )

                # --- —Ç–µ–∫—Å—Ç–æ–≤—ã–π –¥—É–±–ª—å –¥–ª—è A0‚ÄìA2 (plain, –±–µ–∑ HTML) ---
                if level in ["A0", "A1", "A2"]:
                    try:
                        await context.bot.send_message(chat_id=chat_id, text=_strip_html(last_text))
                    except Exception:
                        # –º–æ–ª—á–∞ –∏–≥–Ω–æ—Ä–∏—Ä—É–µ–º ‚Äî —ç—Ç–æ –ª–∏—à—å –¥—É–±–ª—å
                        pass

            except Exception:
                logger.exception("[One-shot TTS error]")
                if interface_lang == "ru":
                    await update.message.reply_text("–ü—Ä–æ–∏–∑–æ—à–ª–∞ –æ—à–∏–±–∫–∞ –ø—Ä–∏ –æ–∑–≤—É—á–∫–µ. –ü–æ–ø—Ä–æ–±—É–µ–º –ø–æ–∑–∂–µ.")
                else:
                    await update.message.reply_text("An error occurred while generating audio. Let‚Äôs try later.")
            finally:
                return  # —Ä–µ–∂–∏–º –Ω–µ –º–µ–Ω—è–µ–º

        # === –ü–µ—Ä–µ–∫–ª—é—á–µ–Ω–∏—è —Ä–µ–∂–∏–º–æ–≤ ===
        if is_strict_mode_trigger(user_input, "voice"):
            session["mode"] = "voice"
            msg = MODE_SWITCH_MESSAGES["voice"].get(interface_lang, MODE_SWITCH_MESSAGES["voice"]["en"])
            await update.message.reply_text(msg, reply_markup=get_mode_keyboard("voice", interface_lang))
            return
        if is_strict_mode_trigger(user_input, "text"):
            session["mode"] = "text"
            msg = MODE_SWITCH_MESSAGES["text"].get(interface_lang, MODE_SWITCH_MESSAGES["text"]["en"])
            await update.message.reply_text(msg, reply_markup=get_mode_keyboard("text", interface_lang))
            return

        # –ú—è–≥–∫–∏–µ –ø–æ–¥—Å–∫–∞–∑–∫–∏
        user_text_norm = user_input.lower()
        if any(phrase in user_text_norm for phrase in MODE_TRIGGERS["voice"]):
            if interface_lang == "ru":
                await update.message.reply_text("–ï—Å–ª–∏ —Ö–æ—á–µ—à—å –ø–µ—Ä–µ–π—Ç–∏ –≤ –≥–æ–ª–æ—Å–æ–≤–æ–π —Ä–µ–∂–∏–º ‚Äî –ø—Ä–æ—Å—Ç–æ –Ω–∞–ø–∏—à–∏ <b>–≥–æ–ª–æ—Å</b> üòâ", parse_mode="HTML")
            else:
                await update.message.reply_text("To switch to voice mode, just type <b>voice</b> üòâ", parse_mode="HTML")
            return
        if any(phrase in user_text_norm for phrase in MODE_TRIGGERS["text"]):
            if interface_lang == "ru":
                await update.message.reply_text("–ß—Ç–æ–±—ã –ø–µ—Ä–µ–π—Ç–∏ –≤ —Ç–µ–∫—Å—Ç–æ–≤—ã–π —Ä–µ–∂–∏–º, –Ω–∞–ø–∏—à–∏ <b>—Ç–µ–∫—Å—Ç</b> üôÇ", parse_mode="HTML")
            else:
                await update.message.reply_text("To switch to text mode, type <b>text</b> üôÇ", parse_mode="HTML")
            return

        # –°–æ–∑–¥–∞—Ç–µ–ª—å
        found_trigger = False
        norm_for_creator = re.sub(r"[^\w\s]", "", user_input.lower())
        for trig in CREATOR_TRIGGERS.get(interface_lang, CREATOR_TRIGGERS["en"]):
            if trig in norm_for_creator:
                found_trigger = True
                break
        if found_trigger:
            if interface_lang == "ru":
                reply_text = "üêæ –ú–æ–π —Å–æ–∑–¥–∞—Ç–µ–ª—å ‚Äî @marrona! –î–ª—è –æ–±—Ä–∞—Ç–Ω–æ–π —Å–≤—è–∑–∏ –∏ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–π –∫ —Å–æ—Ç—Ä—É–¥–Ω–∏—á–µ—Å—Ç–≤—É –æ–±—Ä–∞—â–∞–π—Å—è –ø—Ä—è–º–æ –∫ –Ω–µ–π. üå∑"
            else:
                reply_text = "üêæ My creator is @marrona! For feedback or collaboration offers, feel free to contact her directly. üå∑"
            await update.message.reply_text(reply_text)
            return

        # --- –ò—Å—Ç–æ—Ä–∏—è + —Å–∏—Å—Ç–µ–º–Ω—ã–π –ø—Ä–æ–º–ø—Ç ---
        history = session.setdefault("history", [])
        system_prompt = get_system_prompt(style, level, interface_lang, target_lang, mode)
        prompt = [{"role": "system", "content": system_prompt}]
        prompt.extend(history)

        # --- –õ—ë–≥–∫–∞—è –ø–æ—á–∏–Ω–∫–∞ —Å–º–µ—à–∞–Ω–Ω–æ–π —Ñ—Ä–∞–∑—ã (code-switch) ---
        clean_user_input, preface_html = await rewrite_mixed_input(
            user_input, interface_lang, target_lang
        )
        prompt.append({"role": "user", "content": clean_user_input})

        assistant_reply = await ask_gpt(prompt, "gpt-4o")

        # --- –ò—Å—Ç–æ—Ä–∏—è ---
        history.append({"role": "user", "content": clean_user_input})
        history.append({"role": "assistant", "content": assistant_reply})
        if len(history) > MAX_HISTORY_LENGTH:
            history.pop(0)

        # --- –û—Ç–ø—Ä–∞–≤–∫–∞ –æ—Ç–≤–µ—Ç–∞ ---
        final_reply_text = f"{preface_html}\n\n{assistant_reply}" if preface_html else assistant_reply

        if mode == "voice":
            # –í TTS —É—Ö–æ–¥–∏—Ç –¢–û–õ–¨–ö–û —Ü–µ–ª–µ–≤–æ–π —è–∑—ã–∫ ‚Äî –±–µ–∑ –ø—Ä–∏—Å—Ç–∞–≤–∫–∏ –Ω–∞ UI-—è–∑—ã–∫–µ/HTML
            voice_path = synthesize_voice(assistant_reply, LANGUAGE_CODES.get(target_lang, "en-US"), level)
            # --- 1) –æ—Ç–ø—Ä–∞–≤–ª—è–µ–º voice –æ—Ç–¥–µ–ª—å–Ω–æ ---
            try:
                if voice_path:
                    await _send_voice_or_audio(context, chat_id, voice_path)
                else:
                    raise RuntimeError("No TTS data")
            except Exception:
                await context.bot.send_message(
                    chat_id=chat_id,
                    text="‚ö†Ô∏è –ù–µ —É–¥–∞–ª–æ—Å—å –æ—Ç–ø—Ä–∞–≤–∏—Ç—å –≥–æ–ª–æ—Å. –í–æ—Ç —Ç–µ–∫—Å—Ç:\n" + _strip_html(final_reply_text),
                )
            # --- 2) —Ç–µ–∫—Å—Ç–æ–≤—ã–π –¥—É–±–ª—å –¥–ª—è A0‚ÄìA2 (plain, –±–µ–∑ HTML) ---
            if level in ["A0", "A1", "A2"]:
                try:
                    await context.bot.send_message(chat_id=chat_id, text=_strip_html(final_reply_text))
                except Exception:
                    pass
            # –∑–∞–ø–æ–º–∏–Ω–∞–µ–º —á–∏—Å—Ç–æ —Ü–µ–ª–µ–≤–æ–π —Ç–µ–∫—Å—Ç –¥–ª—è "–æ–∑–≤—É—á—å"
            session["last_assistant_text"] = assistant_reply
        else:
            await update.message.reply_text(final_reply_text, parse_mode="HTML")
            session["last_assistant_text"] = assistant_reply

    except Exception:
        logger.exception("[–û–®–ò–ë–ö–ê –≤ handle_message]")
        await context.bot.send_message(chat_id=chat_id, text="‚ö†Ô∏è –ß—Ç–æ-—Ç–æ –ø–æ—à–ª–æ –Ω–µ —Ç–∞–∫! –ü–æ–ø—Ä–æ–±—É–π –µ—â—ë —Ä–∞–∑ –∏–ª–∏ –ø–µ—Ä–µ–∑–∞–ø—É—Å—Ç–∏ –±–æ—Ç–∞ –∫–æ–º–∞–Ω–¥–æ–π /start.")
