import os
import time
import random
import re
import tempfile
import openai
import logging
from telegram import Update
from telegram.ext import ContextTypes
from config.config import ADMINS

from components.gpt_client import ask_gpt
from components.voice import synthesize_voice
from components.mode import MODE_SWITCH_MESSAGES, get_mode_keyboard
from state.session import user_sessions
from handlers.chat.prompt_templates import get_system_prompt, START_MESSAGE, MATT_INTRO, INTRO_QUESTIONS
from components.triggers import CREATOR_TRIGGERS, MODE_TRIGGERS
from components.triggers import is_strict_mode_trigger, is_strict_say_once_trigger  # <-- –¥–æ–±–∞–≤–ª–µ–Ω–æ

logger = logging.getLogger(__name__)

MAX_HISTORY_LENGTH = 40
RATE_LIMIT_SECONDS = 1.5

LANGUAGE_CODES = {
    "en": "en-US",
    "fr": "fr-FR",
    "de": "de-DE",
    "es": "es-ES",
    "ru": "ru-RU",
    "sv": "sv-SE",
    "fi": "fi-FI"
}

def get_greeting_name(lang: str) -> str:
    return "Matt" if lang == "en" else "–ú—ç—Ç—Ç"

def _sanitize_user_text(text: str, max_len: int = 2000) -> str:
    text = (text or "").strip()   # ‚Üê FIX: –±—ã–ª–æ .trim()
    if len(text) > max_len:
        text = text[:max_len]
    return text

def _send_voice_or_audio(context: ContextTypes.DEFAULT_TYPE, chat_id: int, file_path: str):
    """
    –ï—Å–ª–∏ .ogg ‚Äî —à–ª—ë–º –∫–∞–∫ voice, –∏–Ω–∞—á–µ (.mp3) ‚Äî –∫–∞–∫ audio.
    –≠—Ç–æ –∏—Å–∫–ª—é—á–∞–µ—Ç ¬´—Ä–æ–≤–Ω—É—é –ª–∏–Ω–∏—é¬ª, –µ—Å–ª–∏ TTS –≤–µ—Ä–Ω—É–ª –Ω–µ-OGG.
    """
    async def _inner():
        if file_path.lower().endswith(".ogg"):
            with open(file_path, "rb") as vf:
                await context.bot.send_voice(chat_id=chat_id, voice=vf)
        else:
            with open(file_path, "rb") as af:
                await context.bot.send_audio(chat_id=chat_id, audio=af)
    return _inner()

# --- –ì–ª–∞–≤–Ω—ã–π message handler ---
async def handle_message(update: Update, context: ContextTypes.DEFAULT_TYPE):
    chat_id = update.effective_chat.id
    session = user_sessions.setdefault(chat_id, {})

    # === –í–°–¢–ê–í–ö–ê: –µ—Å–ª–∏ –∂–¥—ë–º –ø—Ä–æ–º–æ–∫–æ–¥, –æ—Ç–¥–∞—ë–º –≤ –æ–±—Ä–∞–±–æ—Ç—á–∏–∫ –ø—Ä–æ–º–æ–∫–æ–¥–∞ –∏ –≤—ã—Ö–æ–¥–∏–º ===
    try:
        stage = session.get("onboarding_stage")
    except Exception:
        stage = None

    if stage == "awaiting_promo":
        from components.onboarding import promo_code_message
        return await promo_code_message(update, context)
    # === –ö–û–ù–ï–¶ –í–°–¢–ê–í–ö–ò ===

    # --- RATE LIMITING ---
    now = time.time()
    last_time = session.get("last_message_time", 0)
    if now - last_time < RATE_LIMIT_SECONDS:
        await context.bot.send_message(chat_id=chat_id, text="‚è≥ –ü–æ–≥–æ–¥–∏, –¥—É–º–∞—é üôÇ")
        return
    session["last_message_time"] = now

    try:
        # --- session defaults ---
        session.setdefault("interface_lang", "en")
        session.setdefault("target_lang", "en")
        session.setdefault("level", "A2")
        session.setdefault("mode", "text")
        session.setdefault("style", "casual")

        # --- –ü–æ–ª—É—á–∞–µ–º –≤—Å–µ –∑–Ω–∞—á–µ–Ω–∏—è –∏–∑ —Å–µ—Å—Å–∏–∏ –¥–ª—è —É–Ω–∏–≤–µ—Ä—Å–∞–ª—å–Ω–æ–≥–æ –¥–æ—Å—Ç—É–ø–∞ ---
        interface_lang = session["interface_lang"]
        target_lang = session["target_lang"]
        level = session["level"]
        mode = session["mode"]
        style = session["style"]

        # === –û–ë–†–ê–ë–û–¢–ö–ê –í–•–û–î–Ø–©–ï–ì–û –°–û–û–ë–©–ï–ù–ò–Ø: —Ç–µ–∫—Å—Ç –∏–ª–∏ –≥–æ–ª–æ—Å ===
        if update.message.voice:
            # --- –†–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏–µ –≥–æ–ª–æ—Å–∞ —á–µ—Ä–µ–∑ Whisper ---
            voice_file = await context.bot.get_file(update.message.voice.file_id)
            with tempfile.NamedTemporaryFile(suffix=".ogg", delete=False) as tf:
                await voice_file.download_to_drive(tf.name)
                audio_path = tf.name

            try:
                with open(audio_path, "rb") as f:
                    transcript = openai.audio.transcriptions.create(
                        model="whisper-1",
                        file=f,
                        response_format="text"
                    )
                user_input = (transcript or "").strip()
                logger.info("Whisper recognized text: %r", user_input)
            except Exception:
                await context.bot.send_message(chat_id=chat_id, text="‚ùóÔ∏è–û—à–∏–±–∫–∞ —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏—è –≥–æ–ª–æ—Å–∞. –ü–æ–ø—Ä–æ–±—É–π –µ—â—ë —Ä–∞–∑.")
                logger.exception("[Whisper Error]")
                user_input = ""
            finally:
                try:
                    os.remove(audio_path)
                except Exception as e_rm:
                    logger.warning("Failed to remove temp audio: %s", e_rm)
        else:
            # --- –û–±—ã—á–Ω—ã–π —Ç–µ–∫—Å—Ç ---
            user_input = update.message.text or ""

        # –°–∞–Ω–∏—Ç–∏–∑–∞—Ü–∏—è —Ç–µ–∫—Å—Ç–∞ –æ—Ç —Å–ª–∏—à–∫–æ–º –¥–ª–∏–Ω–Ω—ã—Ö —Å–æ–æ–±—â–µ–Ω–∏–π
        user_input = _sanitize_user_text(user_input, max_len=2000)

        # --- –ï—Å–ª–∏ –ø—É—Å—Ç–æ–π —Ç–µ–∫—Å—Ç ‚Äî —Å–æ–æ–±—â–∞–µ–º –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—é –∏ –≤—ã—Ö–æ–¥–∏–º ---
        if not user_input:
            await context.bot.send_message(chat_id=chat_id, text="‚ùóÔ∏è–ü–æ—Ö–æ–∂–µ, —Å–æ–æ–±—â–µ–Ω–∏–µ –Ω–µ —Ä–∞—Å–ø–æ–∑–Ω–∞–Ω–æ. –°–∫–∞–∂–∏ —á—Ç–æ-–Ω–∏–±—É–¥—å –µ—â—ë üôÇ")
            return

        # === –†–∞–∑–æ–≤–∞—è –æ–∑–≤—É—á–∫–∞ –±–µ–∑ —Å–º–µ–Ω—ã —Ä–µ–∂–∏–º–∞ ===
        if is_strict_say_once_trigger(user_input, interface_lang):
            last_text = session.get("last_assistant_text")
            if not last_text:
                if interface_lang == "ru":
                    await update.message.reply_text("–ü–æ–∫–∞ –º–Ω–µ –Ω–µ—á–µ–≥–æ –æ–∑–≤—É—á–∏—Ç—å. –°–Ω–∞—á–∞–ª–∞ –¥–æ–∂–¥–∏—Å—å –º–æ–µ–≥–æ –æ—Ç–≤–µ—Ç–∞, –∞ –ø–æ—Ç–æ–º –Ω–∞–ø–∏—à–∏ ¬´–æ–∑–≤—É—á—å¬ª.")
                else:
                    await update.message.reply_text("I have nothing to voice yet. First wait for my reply, then say ‚Äúvoice it‚Äù.")
                return

            try:
                voice_path = synthesize_voice(
                    last_text,
                    LANGUAGE_CODES.get(target_lang, "en-US"),
                    level  # (—Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç—å –ø–æ —Å—Ç–∏–ª—é/—É—Ä–æ–≤–Ω—é —É—á—Ç–µ–Ω–∞ –≤ voice.py)
                )
                if voice_path:
                    await _send_voice_or_audio(context, chat_id, voice_path)
                    if level in ["A0", "A1", "A2"]:
                        await context.bot.send_message(chat_id=chat_id, text=last_text)
                else:
                    if interface_lang == "ru":
                        await update.message.reply_text("–ù–µ –ø–æ–ª—É—á–∏–ª–æ—Å—å –æ–∑–≤—É—á–∏—Ç—å. –ü–æ–ø—Ä–æ–±—É–π –µ—â—ë —Ä–∞–∑ —á—É—Ç—å –ø–æ–∑–∂–µ.")
                    else:
                        await update.message.reply_text("Couldn‚Äôt generate audio. Please try again later.")
            except Exception:
                logger.exception("[One-shot TTS error]")
                if interface_lang == "ru":
                    await update.message.reply_text("–ü—Ä–æ–∏–∑–æ—à–ª–∞ –æ—à–∏–±–∫–∞ –ø—Ä–∏ –æ–∑–≤—É—á–∫–µ. –ü–æ–ø—Ä–æ–±—É–µ–º –ø–æ–∑–∂–µ.")
                else:
                    await update.message.reply_text("An error occurred while generating audio. Let‚Äôs try later.")
            finally:
                return  # —Ä–µ–∂–∏–º –Ω–µ –º–µ–Ω—è–µ–º

        # === –£–Ω–∏–≤–µ—Ä—Å–∞–ª—å–Ω–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞ —Ç—Ä–∏–≥–≥–µ—Ä–æ–≤ ===
        if is_strict_mode_trigger(user_input, "voice"):
            session["mode"] = "voice"
            msg = MODE_SWITCH_MESSAGES["voice"].get(interface_lang, MODE_SWITCH_MESSAGES["voice"]["en"])
            await update.message.reply_text(msg, reply_markup=get_mode_keyboard("voice", interface_lang))
            return

        if is_strict_mode_trigger(user_input, "text"):
            session["mode"] = "text"
            msg = MODE_SWITCH_MESSAGES["text"].get(interface_lang, MODE_SWITCH_MESSAGES["text"]["en"])
            await update.message.reply_text(msg, reply_markup=get_mode_keyboard("text", interface_lang))
            return

        # –ú—è–≥–∫–∏–µ –ø–æ–¥—Å–∫–∞–∑–∫–∏ (–Ω–µ —É—Ö–æ–¥–∏–º –≤ GPT)
        user_text_norm = user_input.lower()
        if any(phrase in user_text_norm for phrase in MODE_TRIGGERS["voice"]):
            if interface_lang == "ru":
                await update.message.reply_text("–ï—Å–ª–∏ —Ö–æ—á–µ—à—å –ø–µ—Ä–µ–π—Ç–∏ –≤ –≥–æ–ª–æ—Å–æ–≤–æ–π —Ä–µ–∂–∏–º ‚Äî –ø—Ä–æ—Å—Ç–æ –Ω–∞–ø–∏—à–∏ **–≥–æ–ª–æ—Å** üòâ", parse_mode="Markdown")
            else:
                await update.message.reply_text("To switch to voice mode, just type **voice** üòâ", parse_mode="Markdown")
            return

        if any(phrase in user_text_norm for phrase in MODE_TRIGGERS["text"]):
            if interface_lang == "ru":
                await update.message.reply_text("–ß—Ç–æ–±—ã –ø–µ—Ä–µ–π—Ç–∏ –≤ —Ç–µ–∫—Å—Ç–æ–≤—ã–π —Ä–µ–∂–∏–º, –Ω–∞–ø–∏—à–∏ **—Ç–µ–∫—Å—Ç** üôÇ", parse_mode="Markdown")
            else:
                await update.message.reply_text("To switch to text mode, type **text** üôÇ", parse_mode="Markdown")
            return

        # --- –ó–∞–ø—Ä–æ—Å –ø—Ä–æ —Å–æ–∑–¥–∞—Ç–µ–ª—è/—Ä–∞–∑—Ä–∞–±–æ—Ç—á–∏–∫–∞ ---
        found_trigger = False
        norm_for_creator = re.sub(r'[^\w\s]', '', user_input.lower())
        for trig in CREATOR_TRIGGERS.get(interface_lang, CREATOR_TRIGGERS["en"]):
            if trig in norm_for_creator:
                found_trigger = True
                break

        if found_trigger:
            if interface_lang == "ru":
                reply_text = "üêæ –ú–æ–π —Å–æ–∑–¥–∞—Ç–µ–ª—å ‚Äî @marrona! –î–ª—è –æ–±—Ä–∞—Ç–Ω–æ–π —Å–≤—è–∑–∏ –∏ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–π –∫ —Å–æ—Ç—Ä—É–¥–Ω–∏—á–µ—Å—Ç–≤—É –æ–±—Ä–∞—â–∞–π—Å—è –ø—Ä—è–º–æ –∫ –Ω–µ–π. üå∑"
            else:
                reply_text = "üêæ My creator is @marrona! For feedback or collaboration offers, feel free to contact her directly. üå∑"
            await update.message.reply_text(reply_text)
            return

        # --- –ü–µ—Ä–µ–ø–∏—Å–∫–∞ —Å GPT ---
        history = session.setdefault("history", [])

        # --- –§–æ—Ä–º–∏—Ä—É–µ–º system prompt ---
        system_prompt = get_system_prompt(style, level, interface_lang, target_lang, mode)
        prompt = [{"role": "system", "content": system_prompt}]
        for msg in history:
            prompt.append(msg)
        prompt.append({"role": "user", "content": user_input})

        assistant_reply = await ask_gpt(prompt, "gpt-4o")

        # --- –ò—Å—Ç–æ—Ä–∏—è –ø–µ—Ä–µ–ø–∏—Å–∫–∏ ---
        history.append({"role": "user", "content": user_input})
        history.append({"role": "assistant", "content": assistant_reply})
        if len(history) > MAX_HISTORY_LENGTH:
            history.pop(0)

        # --- –û—Ç–≤–µ—Ç: —Ç–µ–∫—Å—Ç –∏–ª–∏ –≥–æ–ª–æ—Å ---
        if mode == "voice":
            voice_path = synthesize_voice(assistant_reply, LANGUAGE_CODES.get(target_lang, "en-US"), level)
            try:
                if voice_path:
                    await _send_voice_or_audio(context, chat_id, voice_path)
                else:
                    raise RuntimeError("No TTS data")
                if level in ["A0", "A1", "A2"]:
                    await context.bot.send_message(chat_id=chat_id, text=assistant_reply)
            except Exception:
                # —Ñ–æ–ª–±—ç–∫ –Ω–∞ —Ç–µ–∫—Å—Ç
                await context.bot.send_message(chat_id=chat_id, text="‚ö†Ô∏è –ù–µ —É–¥–∞–ª–æ—Å—å –æ—Ç–ø—Ä–∞–≤–∏—Ç—å –≥–æ–ª–æ—Å–æ–≤–æ–µ —Å–æ–æ–±—â–µ–Ω–∏–µ. –í–æ—Ç —Ç–µ–∫—Å—Ç:\n" + assistant_reply)
            finally:
                # –≤–∞–∂–Ω–æ —Ñ–∏–∫—Å–∏—Ä–æ–≤–∞—Ç—å –ø–æ—Å–ª–µ–¥–Ω–∏–π –æ—Ç–≤–µ—Ç –≤—Å–µ–≥–¥–∞
                session["last_assistant_text"] = assistant_reply
        else:
            await update.message.reply_text(assistant_reply)
            session["last_assistant_text"] = assistant_reply  # —Ñ–∏–∫—Å–∏—Ä—É–µ–º –ø–æ—Å–ª–µ–¥–Ω–∏–π –æ—Ç–≤–µ—Ç –∞—Å—Å–∏—Å—Ç–µ–Ω—Ç–∞

    except Exception:
        logger.exception("[–û–®–ò–ë–ö–ê –≤ handle_message]")
        await context.bot.send_message(chat_id=chat_id, text="‚ö†Ô∏è –ß—Ç–æ-—Ç–æ –ø–æ—à–ª–æ –Ω–µ —Ç–∞–∫! –ü–æ–ø—Ä–æ–±—É–π –µ—â—ë —Ä–∞–∑ –∏–ª–∏ –ø–µ—Ä–µ–∑–∞–ø—É—Å—Ç–∏ –±–æ—Ç–∞ –∫–æ–º–∞–Ω–¥–æ–π /start.")
